
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="index, follow" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="./theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="./theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="./theme/font-awesome/css/font-awesome.min.css">





<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87206506-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Microsoft EDGE -->
    <meta name="msapplication-TileColor" content="#333333">

<meta name="author" content="Matt Jones" />
<meta name="description" content="Selenium &amp; BeautifulSoup are Python packages used to control web browsers and parse website code. Here is how I used these packages to automate the process of copy/pasting table data from a website and saving into a text file." />
<meta name="keywords" content="">

<meta property="og:site_name" content="MJData"/>
<meta property="og:title" content="Web Scraping w/ Selenium &amp; BeautifulSoup"/>
<meta property="og:description" content="Selenium &amp; BeautifulSoup are Python packages used to control web browsers and parse website code. Here is how I used these packages to automate the process of copy/pasting table data from a website and saving into a text file."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./web-scraping-w-selenium-beautifulsoup.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-08-27 00:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="./author/matt-jones.html">
<meta property="article:section" content="Python"/>
<meta property="og:image" content="./images/webscrape.png">

  <title>MJData &ndash; Web Scraping w/ Selenium &amp; BeautifulSoup</title>

<!-- Google Tag Manager -->
<script>
  (function(w,d,s,l,i){
    w[l]=w[l]||[];
    w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});
    var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';
    j.async=true;
    j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;
    f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T6SQGGH');
</script>
<!-- End Google Tag Manager --></head>
<body>
<!-- Google Tag Manager -->
<noscript>
  <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T6SQGGH" height="0" width="0" style="display:none;visibility:hidden"></iframe>
</noscript>
<!-- End Google Tag Manager -->  <aside>
    <div>
      <a href=".">
        <img src="./theme/img/profile.jpeg" alt="Matt Jones" title="Matt Jones">
      </a>
      <h1><a href=".">Matt Jones</a></h1>

<p>Data Analyst</p>

      <ul class="social">
        <li><a class="sc-github" href="https://github.com/ma24jones" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-linkedin" href="https://www.linkedin.com/in/matthew-jones-51683814/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href=".">    Home
</a>

      <a href="./about.html">ABOUT</a>


    </nav>

<article class="single">
  <header>
      
    <h1 id="web-scraping-w-selenium-beautifulsoup">Web Scraping w/ Selenium & BeautifulSoup</h1>
    <p>
          Posted on Tue 27 August 2019 in <a href="./category/python.html">Python</a>


    </p>
  </header>

  
    <img src="./images/webscrape.png" alt="">

  <div>
    <h1>Scenario</h1>
<p>I inherited a report at work that required going to a specific url, logging in with a username &amp; password, selecting some prompts, and then copy/pasting the contents of a table into a text file.</p>
<p>First thing that entered my mind while being trained on the process of the new report was...WEB SCRAPING!</p>
<p>So this post will explain how I went about automating this process using Python along with Selenium and BeautifulSoup.</p>
<h2>Initital Setup</h2>
<p>To start I installed the following packages...</p>
<ul>
<li>pip install selenium</li>
<li>pip install beautifulsoup4</li>
<li>pip install pandas</li>
</ul>
<p>I also installed the <a href="https://chromedriver.chromium.org">chromedriver.exe</a> and saved it to the same path where the python script was located.</p>
<h2>Imports</h2>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="k">as</span> <span class="n">bs</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">time</span>
</pre></div>


<p>In addition to the selenium and beautiful soup packages, I am importing pandas so I can create a DataFrame with the content I am scraping and importing time so I can strategically add pauses to my code while webpages load.</p>
<h2>Web Driver</h2>
<div class="highlight"><pre><span></span>driver = webdriver.Chrome()
url = &lt;&quot;Your URL Here&quot;&gt;
driver.get(url)
</pre></div>


<p>As mentioned before, the browser I am working with is Google Chrome, so with the chromedriver.exe I am using the Selenium webdriver to interact with the browser.</p>
<h2>Login</h2>
<div class="highlight"><pre><span></span>my_username = &lt;&#39;Your Username&#39;&gt;
my_password = &lt;&#39;Your Password&#39;&gt;

time.sleep(3) #Give page time to load

username.send_keys(my_username)
password.send_keys(my_password)

submitButton = driver.find_element_by_id(&quot;login&quot;)
submitButton.click()
</pre></div>


<p>My situation did require me to login with a username and password.  In order to do this I had to "inspect" the login page to locate the specific form elements an login button.</p>
<p>I found that the name of the username input box was conveniently called "username", so I utilized 'username.send_keys(my_username)' where 'my_username' was a variable that contained my username.</p>
<p>I did the same thing with my password by using 'password.send_keys(my_password)'.</p>
<p>To submit my credentials I located the button's id and used the driver.find_element_by_id() function and passed in "login".</p>
<h2>Dropdown</h2>
<div class="highlight"><pre><span></span>driver.find_element_by_xpath(&#39;Your xpath here&#39;).click()
driver.find_element_by_name(&#39;find&#39;).click()
</pre></div>


<p>After logging in, I had to make a selection from a dropdown menu and click another button.</p>
<p>To locate both of these elements, this time I used 'driver.find_element_by_xpath()' and 'driver.find_element_by_name()' after inspecting the page.</p>
<p>I then used '.click()' to accomplish the selection and submission.</p>
<h2>New Window</h2>
<div class="highlight"><pre><span></span>driver.switch_to.window(driver.window_handles[1])
</pre></div>


<p>The dropdown selection resulted in a new tab opening up and displaying the report I needed.</p>
<p>This is where I got stuck a little bit...</p>
<p>The code was still refering to the initial tab that opened up, so I needed to use 'driver.switch_to.window(driver.window_handles[1]) in order to point the code to the correct tab.</p>
<h2>Parse HTML</h2>
<div class="highlight"><pre><span></span>soup = bs(driver.page_source, &#39;html.parser&#39;)

table_rows = soup.find_all(&#39;tr&#39;)

data = []
for tr in table_rows:
    td = tr.find_all(&#39;td&#39;)
    row = [i.text for i in td]
    data. append(row)
</pre></div>


<p>Now that I navigated to the data I needed to scrape, I used BeautifulSoup to grab the page source and parse the html.  The page source revealed that the data needed was wrapped in a table.</p>
<p>So after some googling I found some code that used 'soup.find_all()' to locate the the table rows (tr) and table data (td) and append them into an empty list using a loop.</p>
<h2>Pass Into Pandas DataFrame</h2>
<div class="highlight"><pre><span></span><span class="s s-Atom">data</span> <span class="o">=</span> <span class="s s-Atom">pd</span><span class="p">.</span><span class="nv">DataFrame</span><span class="p">(</span><span class="s s-Atom">data</span><span class="p">)</span>
<span class="s s-Atom">data</span> <span class="o">=</span> <span class="s s-Atom">data</span><span class="p">[</span><span class="mi">3</span><span class="p">:-</span><span class="mi">4</span><span class="p">]</span> <span class="s s-Atom">#</span><span class="nv">Strip</span> <span class="s s-Atom">unecessary</span> <span class="s s-Atom">rows</span>

<span class="s s-Atom">data</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="s s-Atom">r&#39;yourPath\yourFile.txt&#39;</span><span class="p">,</span> <span class="s s-Atom">header</span><span class="o">=</span><span class="nv">None</span><span class="p">,</span> <span class="s s-Atom">inde</span><span class="o">=</span><span class="nv">None</span><span class="p">,</span> <span class="s s-Atom">sep=&#39;\t&#39;</span><span class="p">))</span>
</pre></div>


<p>After I had my list that contained my table data, I stored it into a Pandas DataFrame and used 'to_csv()' to save the contents as a .txt file.</p>
<h2>Full Code Example</h2>
<div class="highlight"><pre><span></span><span class="s s-Atom">from</span> <span class="s s-Atom">selenium</span> <span class="s s-Atom">import</span> <span class="s s-Atom">webdriver</span>
<span class="s s-Atom">from</span> <span class="s s-Atom">bs4</span> <span class="s s-Atom">import</span> <span class="nv">BeautifulSoup</span> <span class="s s-Atom">as</span> <span class="s s-Atom">bs</span>
<span class="s s-Atom">import</span> <span class="s s-Atom">pandas</span> <span class="s s-Atom">as</span> <span class="s s-Atom">pd</span>
<span class="s s-Atom">import</span> <span class="s s-Atom">time</span>

<span class="s s-Atom">driver</span> <span class="o">=</span> <span class="s s-Atom">webdriver</span><span class="p">.</span><span class="nv">Chrome</span><span class="p">()</span>
<span class="s s-Atom">url</span> <span class="o">=</span> <span class="s s-Atom">&lt;</span><span class="s2">&quot;Your URL Here&quot;</span><span class="o">&gt;</span>
<span class="s s-Atom">driver</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="s s-Atom">url</span><span class="p">)</span>

<span class="c1">#Login</span>
<span class="s s-Atom">my_username</span> <span class="o">=</span> <span class="s s-Atom">&lt;&#39;Your Username&#39;</span><span class="o">&gt;</span>
<span class="s s-Atom">my_password</span> <span class="o">=</span> <span class="s s-Atom">&lt;&#39;Your Password&#39;</span><span class="o">&gt;</span>

<span class="s s-Atom">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="s s-Atom">#</span><span class="nv">Give</span> <span class="s s-Atom">page</span> <span class="s s-Atom">time</span> <span class="s s-Atom">to</span> <span class="s s-Atom">load</span>

<span class="s s-Atom">username</span><span class="p">.</span><span class="nf">send_keys</span><span class="p">(</span><span class="s s-Atom">my_username</span><span class="p">)</span>
<span class="s s-Atom">password</span><span class="p">.</span><span class="nf">send_keys</span><span class="p">(</span><span class="s s-Atom">my_password</span><span class="p">)</span>

<span class="s s-Atom">submitButton</span> <span class="o">=</span> <span class="s s-Atom">driver</span><span class="p">.</span><span class="nf">find_element_by_id</span><span class="p">(</span><span class="s2">&quot;login&quot;</span><span class="p">)</span>
<span class="s s-Atom">submitButton</span><span class="p">.</span><span class="nf">click</span><span class="p">()</span>

<span class="c1">#Dropdown selection</span>
<span class="s s-Atom">driver</span><span class="p">.</span><span class="nf">find_element_by_xpath</span><span class="p">(</span><span class="s s-Atom">&#39;Your xpath here&#39;</span><span class="p">).</span><span class="nf">click</span><span class="p">()</span>
<span class="s s-Atom">driver</span><span class="p">.</span><span class="nf">find_element_by_name</span><span class="p">(</span><span class="s s-Atom">&#39;find&#39;</span><span class="p">).</span><span class="nf">click</span><span class="p">()</span>

<span class="c1">#New Tab</span>
<span class="s s-Atom">driver</span><span class="p">.</span><span class="s s-Atom">switch_to</span><span class="p">.</span><span class="nf">window</span><span class="p">(</span><span class="s s-Atom">driver</span><span class="p">.</span><span class="s s-Atom">window_handles</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1">#Parse HTML with beautifulSoup</span>
<span class="s s-Atom">soup</span> <span class="o">=</span> <span class="nf">bs</span><span class="p">(</span><span class="s s-Atom">driver</span><span class="p">.</span><span class="s s-Atom">page_source</span><span class="p">,</span> <span class="s s-Atom">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="s s-Atom">table_rows</span> <span class="o">=</span> <span class="s s-Atom">soup</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s s-Atom">&#39;tr&#39;</span><span class="p">)</span>

<span class="s s-Atom">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="s s-Atom">for</span> <span class="s s-Atom">tr</span> <span class="s s-Atom">in</span> <span class="s s-Atom">table_rows:</span>
    <span class="s s-Atom">td</span> <span class="o">=</span> <span class="s s-Atom">tr</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s s-Atom">&#39;td&#39;</span><span class="p">)</span>
    <span class="s s-Atom">row</span> <span class="o">=</span> <span class="p">[</span><span class="s s-Atom">i</span><span class="p">.</span><span class="s s-Atom">text</span> <span class="s s-Atom">for</span> <span class="s s-Atom">i</span> <span class="s s-Atom">in</span> <span class="s s-Atom">td</span><span class="p">]</span>
    <span class="s s-Atom">data</span><span class="p">.</span> <span class="nf">append</span><span class="p">(</span><span class="s s-Atom">row</span><span class="p">)</span>

<span class="c1">#Pandas to_csv</span>
<span class="s s-Atom">data</span> <span class="o">=</span> <span class="s s-Atom">pd</span><span class="p">.</span><span class="nv">DataFrame</span><span class="p">(</span><span class="s s-Atom">data</span><span class="p">)</span>
<span class="s s-Atom">data</span> <span class="o">=</span> <span class="s s-Atom">data</span><span class="p">[</span><span class="mi">3</span><span class="p">:-</span><span class="mi">4</span><span class="p">]</span> <span class="s s-Atom">#</span><span class="nv">Strip</span> <span class="s s-Atom">unecessary</span> <span class="s s-Atom">rows</span>

<span class="s s-Atom">data</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="s s-Atom">r&#39;yourPath\yourFile.txt&#39;</span><span class="p">,</span> <span class="s s-Atom">header</span><span class="o">=</span><span class="nv">None</span><span class="p">,</span> <span class="s s-Atom">inde</span><span class="o">=</span><span class="nv">None</span><span class="p">,</span> <span class="s s-Atom">sep=&#39;\t&#39;</span><span class="p">))</span>
</pre></div>


<p>Happy Scraping!</p>
  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>





</article>

    <footer>
<p>
  &copy;  2016 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
           src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " MJData ",
  "url" : ".",
  "image": "",
  "description": "Exploring Data With Python"
}
</script>

</body>
</html>